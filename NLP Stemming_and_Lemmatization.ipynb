{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Title: Stemming and Lemmatization in NLP using NLTK"
      ],
      "metadata": {
        "id": "rinhxPjcJoL9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Stemming"
      ],
      "metadata": {
        "id": "HrLWwZ37aRJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming** is used in **text processing** in NLP is the process of reducing a word to their root form called 'stem'.\n",
        "\n",
        "**For example**, the stemming process might convert words like \"running,\" \"runner,\" and \"ran\" to the common stem \"run.\""
      ],
      "metadata": {
        "id": "UwAMxqLtJtV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are different techniques of stemming performed in this notebook:\n",
        "\n",
        "- PorterStemmer\n",
        "- RegexStemmer\n",
        "- SnowBallStemmer"
      ],
      "metadata": {
        "id": "CbEy7uEoMa9n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (i). Porter Stemmer\n",
        "\n",
        "Developed by Martin Porter, the Porter stemming algorithm is one of the oldest and widely used stemming algorithms"
      ],
      "metadata": {
        "id": "zZHKDUPVMpTB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I_ZIVS55Jcxe"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "tpoW9OzuNZ0f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"eating\",\"eaten\",\"eater\",\"congratulations\",\"lovely\",\"lover\",\"loving\"]"
      ],
      "metadata": {
        "id": "p6gGdOElM-6O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This technique performs well, but in some cases it have disadvantage because it completely change the meaning of word such as here 'congratulations' is stem into 'congratul', which is different word."
      ],
      "metadata": {
        "id": "ZiyAqyNdNfd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + \"---->\" + stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDD8NcmJNGhN",
        "outputId": "ea2cdd9c-f467-4636-f2d0-6ab2e2ef68c9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating---->eat\n",
            "eaten---->eaten\n",
            "eater---->eater\n",
            "congratulations---->congratul\n",
            "lovely---->love\n",
            "lover---->lover\n",
            "loving---->love\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (ii). RegexpStemmer:\n",
        "\n",
        "Regex (regular expression) stemming involves using regular expressions to find and remove suffixes from words. Developers can customize the regular expressions based on the specific requirements of their text processing tasks."
      ],
      "metadata": {
        "id": "E1Rhfp9AN1pX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer"
      ],
      "metadata": {
        "id": "ZTFkUGIoNTS5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer = RegexpStemmer('^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$', min=5)"
      ],
      "metadata": {
        "id": "E608f9t7OIlM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reg_stemmer.stem(\"eates\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUPg4z3FOL_p",
        "outputId": "553d231d-d813-46d2-983c-0b7a867bd51b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer.stem(\"lover\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1SO6eZM5Owu8",
        "outputId": "7715553f-e7ab-4576-eb30-5d9dbfe69b74"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (iii). SnowBall Stemmer:\n",
        "\n",
        "Snowball is a language-specific stemming algorithm developed by Martin Porter, and it is an improvement upon the original Porter stemming algorithm."
      ],
      "metadata": {
        "id": "xSmHpZsRPuws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer"
      ],
      "metadata": {
        "id": "6TmxLmxNPr5v"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snow_ball_stemmer = SnowballStemmer(\"english\")"
      ],
      "metadata": {
        "id": "Tt7P2zHmP99O"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + \"--->\" + snow_ball_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnXZzlibQL0_",
        "outputId": "79013423-5f71-429d-f291-c128b2b0d05d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating--->eat\n",
            "eaten--->eaten\n",
            "eater--->eater\n",
            "congratulations--->congratul\n",
            "lovely--->love\n",
            "lover--->lover\n",
            "loving--->love\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Difference in PorterStemmer and SnowBallStemmer\n",
        "\n",
        "\n",
        "SnowBallStemmer performs well from PorterStemmer. Also SnowballStemmer support multiple languages but PorterStemmer supports only English language."
      ],
      "metadata": {
        "id": "GhlG2JGSQ-MC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem(\"fairly\"), snow_ball_stemmer.stem(\"fairly\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc-FXaphQUXV",
        "outputId": "418c1a98-79cc-4b30-d78d-8a70fbc484ba"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fairli', 'fair')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem(\"congratulations\"), snow_ball_stemmer.stem(\"congratulations\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l5UVnIIR5Gf",
        "outputId": "6c84c221-8ee3-4b99-bf41-c04c6bf1f9e4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('congratul', 'congratul')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Lemmatization:\n",
        "\n",
        "Lemmatization is also a technique used in NLP, but it goes beyond stemming by reducing words to their \"lemma\" or base form, which is a valid word found in the dictionary. Lemmatization involves considering the context of a word and its part of speech to produce a meaningful base form. Unlike stemming, lemmatization ensures linguistic accuracy but can be computationally more intensive."
      ],
      "metadata": {
        "id": "41qjGUlvSW13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The technique of lemmatization performed in this notebook:\n",
        "\n",
        "- WordNetLemmatizer"
      ],
      "metadata": {
        "id": "YX8JsHMsXn9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"wordnet\")\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_1ZZuFbXlTL",
        "outputId": "b68d1bce-be91-40dc-888f-ebc9e0d15b9f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are pos-tags in lemmatization:\n",
        "\n",
        "- Noun - 'n'\n",
        "- Verb - 'v'\n",
        "- Adjective - 'a'\n",
        "- Adverb - 'r'"
      ],
      "metadata": {
        "id": "ijhIeeZmYoqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "X-HMoG_nX7NC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"goes\", pos=\"v\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TcfTZvvGX9Lf",
        "outputId": "1f45341e-4bc0-49e5-cf5c-78d3ef939ba0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'go'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"goes\", pos=\"n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jcVcGvlVYB_w",
        "outputId": "495a91fe-c04f-430a-c15f-87cd0f027d3b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'go'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"goes\", pos=\"a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "O4n0tRPQZFA7",
        "outputId": "4d7bbfa2-330e-4df7-8cf6-14259351c0ad"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'goes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"goes\", pos=\"r\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SbjxOebrZIb-",
        "outputId": "322cf9e4-e550-4350-b61a-7565ac73ec84"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'goes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + \"--->\" + lemmatizer.lemmatize(word, pos=\"v\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyGSLyh9ZJpr",
        "outputId": "6dfa4314-3117-44d6-fef3-b5e59db5f1cc"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating--->eat\n",
            "eaten--->eat\n",
            "eater--->eater\n",
            "congratulations--->congratulations\n",
            "lovely--->lovely\n",
            "lover--->lover\n",
            "loving--->love\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "End of Code!"
      ],
      "metadata": {
        "id": "DkjZ0-zradgd"
      }
    }
  ]
}