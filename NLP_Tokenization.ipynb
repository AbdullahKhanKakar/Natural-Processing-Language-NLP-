{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Title: Tokenization in NLP\n",
        "\n",
        "\n",
        "> Tokenization is the process of converting the text into smaller units called tokens.\n",
        "\n",
        "\n",
        "\n",
        "### Important key-terms in tokenization:\n",
        "\n",
        "> **Corpus**: Called Paragraph.\n",
        "\n",
        "> **Document**: Called Sentence.\n",
        "\n",
        "> **Vocabulary**: Unique Words."
      ],
      "metadata": {
        "id": "uU7TqlP-VMkA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGpmzRYLOnTr",
        "outputId": "d15b2c9a-d514-42f0-f225-3cc64bd032d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# importing all the necessary libraries required in this notebook\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize, wordpunct_tokenize, TreebankWordTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- First:\n",
        "\n",
        "> **sent_tokenize**: Convert corpus(paragraph) into documents(sentences).\n",
        "\n",
        "- Second:\n",
        "\n",
        "> **word_tokenize, wordpunct_tokenize, TreebankWordTokenizer**: All these techniques, convert corpus(paragraph) into vocabulary(words). But all do it with different approach.\n"
      ],
      "metadata": {
        "id": "2T0LJqhiWRq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = \"\"\"My name is Abdullah Khan's.\n",
        "I am, doing NLP right now! for becomming NLP Engineer.\n",
        "I want to do for best results.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hpCOiogcOwyl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnoTqDtbQ46s",
        "outputId": "c34491f9-8731-4424-dc2c-9ab3b8ea71d1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My name is Abdullah Khan's.\n",
            "I am, doing NLP right now! for becomming NLP Engineer.\n",
            "I want to do for best results.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting paragraph into sentences\n",
        "document = sent_tokenize(corpus)"
      ],
      "metadata": {
        "id": "2UP8wJofQwzp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jr_SOjHgQzMk",
        "outputId": "5780d943-6a5f-4f2e-819d-b281c0286434"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"My name is Abdullah Khan's.\",\n",
              " 'I am, doing NLP right now!',\n",
              " 'for becomming NLP Engineer.',\n",
              " 'I want to do for best results.']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert paragraph into words\n",
        "word_tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfcC-9y4SdXI",
        "outputId": "3ad7aa75-1015-49ce-c617-aa7da7148774"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My',\n",
              " 'name',\n",
              " 'is',\n",
              " 'Abdullah',\n",
              " 'Khan',\n",
              " \"'s\",\n",
              " '.',\n",
              " 'I',\n",
              " 'am',\n",
              " ',',\n",
              " 'doing',\n",
              " 'NLP',\n",
              " 'right',\n",
              " 'now',\n",
              " '!',\n",
              " 'for',\n",
              " 'becomming',\n",
              " 'NLP',\n",
              " 'Engineer',\n",
              " '.',\n",
              " 'I',\n",
              " 'want',\n",
              " 'to',\n",
              " 'do',\n",
              " 'for',\n",
              " 'best',\n",
              " 'results',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert sentences into words\n",
        "for sentence in document:\n",
        "  print(word_tokenize(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRJl4Md9Siaq",
        "outputId": "363aa83e-58c0-499d-a894-0da888da3767"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['My', 'name', 'is', 'Abdullah', 'Khan', \"'s\", '.']\n",
            "['I', 'am', ',', 'doing', 'NLP', 'right', 'now', '!']\n",
            "['for', 'becomming', 'NLP', 'Engineer', '.']\n",
            "['I', 'want', 'to', 'do', 'for', 'best', 'results', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert paragraph into words\n",
        "wordpunct_tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRwkpjLtUDXU",
        "outputId": "b2a8d1b0-a121-42ee-cd50-c6b8c55f9677"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My',\n",
              " 'name',\n",
              " 'is',\n",
              " 'Abdullah',\n",
              " 'Khan',\n",
              " \"'\",\n",
              " 's',\n",
              " '.',\n",
              " 'I',\n",
              " 'am',\n",
              " ',',\n",
              " 'doing',\n",
              " 'NLP',\n",
              " 'right',\n",
              " 'now',\n",
              " '!',\n",
              " 'for',\n",
              " 'becomming',\n",
              " 'NLP',\n",
              " 'Engineer',\n",
              " '.',\n",
              " 'I',\n",
              " 'want',\n",
              " 'to',\n",
              " 'do',\n",
              " 'for',\n",
              " 'best',\n",
              " 'results',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert paragraph into words\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "tokenizer.tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo8M6evYUbkp",
        "outputId": "e01aaaf7-e2de-47cf-d0b5-698002ce4cfe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My',\n",
              " 'name',\n",
              " 'is',\n",
              " 'Abdullah',\n",
              " \"Khan's.\",\n",
              " 'I',\n",
              " 'am',\n",
              " ',',\n",
              " 'doing',\n",
              " 'NLP',\n",
              " 'right',\n",
              " 'now',\n",
              " '!',\n",
              " 'for',\n",
              " 'becomming',\n",
              " 'NLP',\n",
              " 'Engineer.',\n",
              " 'I',\n",
              " 'want',\n",
              " 'to',\n",
              " 'do',\n",
              " 'for',\n",
              " 'best',\n",
              " 'results',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "End of Code!"
      ],
      "metadata": {
        "id": "Trq2nWMyXTBy"
      }
    }
  ]
}