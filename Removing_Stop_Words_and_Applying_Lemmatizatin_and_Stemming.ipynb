{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stop Words:\n",
        "\n",
        "Stop words are a set of commonly used words in a language. Examples of stop words in English are “a,” “the,” “is,” “are,” etc. Stop words are commonly used in Text Mining and Natural Language Processing (NLP) to eliminate words that are so widely used that they carry very little useful information."
      ],
      "metadata": {
        "id": "uvBE8ElNcpul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aim and Objective:\n",
        "\n",
        "- Select a Paragraph,\n",
        "- Remove stop words from it,\n",
        "- Apply stemming, lemmatization techniques:\n",
        "  - Stemming: PorterStemmer, SnowballStemmer\n",
        "  - Lemmatization: WordNetLemmatizer\n",
        "- Count words in stemming and lemmatization"
      ],
      "metadata": {
        "id": "ZISn1439mMhv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "FwitWb9lb0_I"
      },
      "outputs": [],
      "source": [
        "# here is the selected paragraph\n",
        "paragraph = \"\"\"We know the scheme of English subjects for matric classes.\n",
        "In this way, the subject of English has two parts, English A and English B.\n",
        "In this way, the second part is more important and has long questions with more than five marks.\n",
        "However, the Essays and stores cover about 10 marks for both parts.\n",
        "But in some academies, the preference for Essays is also included for the 9th class.\n",
        "Therefore, we are going to provide an Essay on My Country Pakistan for class 9 in this post.\n",
        "So, you can read this post to check the Essay on My Country.\n",
        "Basically, the section of the essay will be included in the next class.\n",
        "But it is also useful to remember for the next class.\n",
        "So, we are going to mention to all students that you can read and learn for school tests and exams.\n",
        "The Essay on My Country consists of more than 200 words in this class.\n",
        "However, the section of the paragraph is also included in the matrix in which the topic My country can come in the final exam.\n",
        "In this way, you can learn this essay to get good marks in your final exam.\n",
        "Moreover, the students can also get other essays from this place for their final exam preparation.\n",
        "In this way, we are covering all important essays that normally come in the annual exam.\n",
        "So, you can explore this website to get all the important Essay of Matric for your English B preparation.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# for converting paragraph into sentences and words\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "# for removing stopwords\n",
        "from nltk.corpus import stopwords\n",
        "# for applying stemming and lemmatization\n",
        "from nltk.stem import PorterStemmer ,SnowballStemmer, WordNetLemmatizer"
      ],
      "metadata": {
        "id": "lepudwe2dh4W"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting paragraph(corpus) into sentences(documents)"
      ],
      "metadata": {
        "id": "2pECxLIEnik1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "eoRWkKIEd1aP"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. PorterStemmer"
      ],
      "metadata": {
        "id": "4AZr6UPIoAeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "porter_stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "fMxCG9jAn4AV"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences)):\n",
        "  words = word_tokenize(sentences[i])\n",
        "  words = [porter_stemmer.stem(word) for word in words if word not in set(stopwords.words(\"english\"))]\n",
        "  sentences[i] = ' '.join(words)"
      ],
      "metadata": {
        "id": "3RjNTfR6n-MX"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k5Z30x_oT14",
        "outputId": "b90a6818-21b3-4d41-9a03-b2a2c1c70629"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['we know scheme english subject matric class .',\n",
              " 'in way , subject english two part , english a english b .',\n",
              " 'in way , second part import long question five mark .',\n",
              " 'howev , essay store cover 10 mark part .',\n",
              " 'but academi , prefer essay also includ 9th class .',\n",
              " 'therefor , go provid essay my countri pakistan class 9 post .',\n",
              " 'so , read post check essay my countri .',\n",
              " 'basic , section essay includ next class .',\n",
              " 'but also use rememb next class .',\n",
              " 'so , go mention student read learn school test exam .',\n",
              " 'the essay my countri consist 200 word class .',\n",
              " 'howev , section paragraph also includ matrix topic my countri come final exam .',\n",
              " 'in way , learn essay get good mark final exam .',\n",
              " 'moreov , student also get essay place final exam prepar .',\n",
              " 'in way , cover import essay normal come annual exam .',\n",
              " 'so , explor websit get import essay matric english b prepar .']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting returning words\n",
        "count = 0\n",
        "for i in range(len(sentences)):\n",
        "  count += len(sentences[i].split(\" \"))\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LccMQLUoWMa",
        "outputId": "6ebea067-94e5-444f-b9bc-bf183bda2020"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. SnowballStemmer"
      ],
      "metadata": {
        "id": "Y581FME_o1dG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "snowball_stemmer = SnowballStemmer(\"english\")"
      ],
      "metadata": {
        "id": "8bK4Kbb0hYda"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences)):\n",
        "  words = word_tokenize(sentences[i])\n",
        "  words = [snowball_stemmer.stem(word) for word in words if word not in set(stopwords.words(\"english\"))]\n",
        "  sentences[i] = ' '.join(words)"
      ],
      "metadata": {
        "id": "1XIutoobfUnM"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ooypgw-0hxVB",
        "outputId": "896cc6e1-8af7-4204-d452-2a3065077904"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['we know scheme english subject matric class .',\n",
              " 'in way , subject english two part , english a english b .',\n",
              " 'in way , second part import long question five mark .',\n",
              " 'howev , essay store cover 10 mark part .',\n",
              " 'but academi , prefer essay also includ 9th class .',\n",
              " 'therefor , go provid essay my countri pakistan class 9 post .',\n",
              " 'so , read post check essay my countri .',\n",
              " 'basic , section essay includ next class .',\n",
              " 'but also use rememb next class .',\n",
              " 'so , go mention student read learn school test exam .',\n",
              " 'the essay my countri consist 200 word class .',\n",
              " 'howev , section paragraph also includ matrix topic my countri come final exam .',\n",
              " 'in way , learn essay get good mark final exam .',\n",
              " 'moreov , student also get essay place final exam prepar .',\n",
              " 'in way , cover import essay normal come annual exam .',\n",
              " 'so , explor websit get import essay matric english b prepar .']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting returning words\n",
        "count = 0\n",
        "for i in range(len(sentences)):\n",
        "  count += len(sentences[i].split(\" \"))\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5_oo0wih6ER",
        "outputId": "0a23dd7a-2a09-4a2a-98b1-81fa39cc4bda"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. WordNetLemmatizer"
      ],
      "metadata": {
        "id": "I30Qj7E4pNs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "vTqqV146puvA",
        "outputId": "8423294c-32d4-4c07-bddb-e6090e491434",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "vY_h0WBGpEnA"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences)):\n",
        "  words = word_tokenize(sentences[i])\n",
        "  words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words(\"english\"))]\n",
        "  sentences[i] = ' '.join(words)"
      ],
      "metadata": {
        "id": "3TkAFccSpVtJ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "id": "Rwz_Iq1vpkiF",
        "outputId": "0e3979e0-486a-4ad0-a0de-822f0a505d0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We know scheme English subject matric class .',\n",
              " 'In way , subject English two part , English A English B .',\n",
              " 'In way , second part important long question five mark .',\n",
              " 'However , Essays store cover 10 mark part .',\n",
              " 'But academy , preference Essays also included 9th class .',\n",
              " 'Therefore , going provide Essay My Country Pakistan class 9 post .',\n",
              " 'So , read post check Essay My Country .',\n",
              " 'Basically , section essay included next class .',\n",
              " 'But also useful remember next class .',\n",
              " 'So , going mention student read learn school test exam .',\n",
              " 'The Essay My Country consists 200 word class .',\n",
              " 'However , section paragraph also included matrix topic My country come final exam .',\n",
              " 'In way , learn essay get good mark final exam .',\n",
              " 'Moreover , student also get essay place final exam preparation .',\n",
              " 'In way , covering important essay normally come annual exam .',\n",
              " 'So , explore website get important Essay Matric English B preparation .']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting returning words\n",
        "count = 0\n",
        "for i in range(len(sentences)):\n",
        "  count += len(sentences[i].split(\" \"))\n",
        "print(count)"
      ],
      "metadata": {
        "id": "I218Yka-pq7N",
        "outputId": "49cd373b-2970-4fbd-a33c-bf4beed5bd6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "End of Code!"
      ],
      "metadata": {
        "id": "NAuck1tVp_2q"
      }
    }
  ]
}